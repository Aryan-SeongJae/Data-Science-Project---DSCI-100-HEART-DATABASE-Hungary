{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4306fd-3465-40e0-8d17-0f4f332e0587",
   "metadata": {},
   "source": [
    "# **Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d1811-944c-423a-b4f3-faf2378be21c",
   "metadata": {},
   "source": [
    "# **SERUM CHOLESTROL AND MAXIMUM HEART RATE ACHIEVED TO DIAGNOSE HEART DISEASE PATIENTS FROM HUNGARY**\n",
    "\n",
    "Aryan Jain, Vibhav "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fab048-b878-4e5f-a53f-13e67e7d5826",
   "metadata": {},
   "source": [
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6fc719-81b5-48ad-8cee-3f5a4f45a7d3",
   "metadata": {},
   "source": [
    "Cardiovascular disease encompasses a spectrum of cardiac conditions originating from malfunctions within the cardiac and vascular systems. Among these, coronary artery disease (CAD) manifests when the arteries responsible for supplying blood to the heart undergo a narrowing process. Numerous risk factors contribute to the predisposition for this malady, including elevated cholesterol levels and the maximum heart rate attained during physiological exertion.\n",
    "\n",
    "Elevated cholesterol levels precipitate the accumulation of lipid deposits within the vasculature, impeding the smooth flow of blood through the arteries. The rupture of these deposits may culminate in the formation of a thrombus, thereby instigating severe cardiovascular events such as myocardial infarction or stroke. Notably, individuals afflicted by heart disease may experience a notable reduction in their maximum heart rate, as indicated by medical insights provided by WebMD in 2002.\n",
    "\n",
    "In light of these considerations, the pertinent query arises: can the likelihood of an individual being afflicted by heart disease be ascertained based on an analysis of serum cholesterol levels and the maximum heart rate achieved? To address this question, we propose the utilization of a k-nearest neighbors (KNN) classifier algorithm, an analytical tool with demonstrated efficacy in pattern recognition and classification tasks. By employing this algorithm, we aim to discern discernible patterns and relationships between the aforementioned physiological parameters and the presence of heart disease in a new patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5459dc14-a8c6-4cfd-add2-1cfade13a79c",
   "metadata": {},
   "source": [
    "Our study involves the utilization of the \"processed.hungarian.data\" dataset extracted from the Heart Disease Database for the predictive assessment of heart disease presence in patients from Cleveland. The dataset comprises several pertinent variables, and our focus is on utilizing the variables \"chol\" (serum cholesterol level) and \"thalach\" (maximum heart rate achieved) as predictive features.\n",
    "\n",
    "The specific columns within the dataset are defined as follows:\n",
    "\n",
    "1. **age**: Age of the patient\n",
    "2. **sex**: Gender of the patient (1 = male, 0 = female)\n",
    "3. **cp**: Chest pain type\n",
    "4. **trestbps**: Resting blood pressure in mmHg\n",
    "5. **chol**: Serum cholesterol level in mg/dl\n",
    "6. **fbs**: Fasting blood sugar > 120 mg/dl? (1 = True, 0 = False)\n",
    "7. **restecg**: Resting electrocardiographic results\n",
    "8. **thalach**: Maximum heart rate achieved\n",
    "9. **exang**: Whether exercise induced angina (1 = True, 0 = False)\n",
    "10. **oldpeak**: ST depression induced by exercise, relative to rest\n",
    "11. **slope**: The slope of the peak exercise ST segment (1 = upslope, 2 = flat, 3 = downslope)\n",
    "12. **ca**: Number of major vessels (0-3) colored by fluoroscopy\n",
    "13. **thal**: Thalassemia classification (3 = normal, 6 = fixed defect, 7 = reversible defect)\n",
    "14. **num**: Diagnosis of heart disease (1, 2, 3, 4 = presence, 0 = no presence)\n",
    "\n",
    "For our analysis, we aim to employ the \"chol\" and \"thalach\" variables as predictors to discern the presence or absence of heart disease in patients. This predictive task aligns with the broader objective of leveraging relevant clinical data to enhance diagnostic capabilities and contribute to the advancement of cardiovascular health assessment methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f19f9d5-a7f9-4ee0-9d9d-9e12a74bba60",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "Data Preprocessing and Exploratory Data Analysis\n",
    "\n",
    "We initiated our study by importing relevant libraries and acquiring the \"processed.cleveland.data\" dataset from an authenticated online source. Subsequently, a meticulous data preprocessing phase ensued, wherein we applied systematic cleaning and tidying procedures to render the dataset amenable for analytical endeavors. This process involved judiciously assigning appropriate column types and introducing a new column labeled as \"diag\" to enhance the interpretability of the data.\n",
    "\n",
    "To facilitate subsequent analytical procedures, we judiciously partitioned the dataset into distinct training and testing sets. It is noteworthy that our analytical focus remained exclusively on the training set until the final stages of the investigation.\n",
    "\n",
    "A comprehensive summary of the training set was generated, laying the groundwork for subsequent predictive modeling. This involved the extraction of key insights and patterns from the training data to inform the desired behavior and performance criteria of our classifier.\n",
    "\n",
    "Visualization emerged as an integral component of our exploratory analysis. Specifically, we employed graphical representations to elucidate the intricate relationship between the variables \"thalac\" (maximum heart rate achieved) and \"chol\" (serum cholesterol level). This visual exploration was pivotal in fostering a nuanced understanding of the distributional characteristics inherent in the dataset, thereby contributing to the refinement of subsequent analytical strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43692b3e-d348-44f9-a599-d7202687fc9b",
   "metadata": {},
   "source": [
    "### Determining Optimal k for K-Nearest Neighbors Classifier\n",
    "\n",
    "The objective of this phase in our investigation is to ascertain the optimal value for the parameter 'k' in the k-nearest neighbors (KNN) algorithm, thereby maximizing the accuracy of our predictive model. The subsequent methodology encapsulates a systematic approach towards achieving this goal.\n",
    "\n",
    "1. **Data Preprocessing and Scaling:**\n",
    "   We commence by applying the recipe function to center and scale the training data, a crucial step in normalizing variables to a standardized range, facilitating robust and unbiased model training.\n",
    "\n",
    "2. **Cross-Validation Technique:**\n",
    "   Cross-validation, an integral aspect of our methodological framework, is executed with ten folds on the training dataset. This deliberate choice of employing ten folds serves to mitigate the influence of the specific observations in the validation set, thus enhancing the robustness and generalizability of our model.\n",
    "\n",
    "3. **K-Nearest Neighbors Model Initialization:**\n",
    "   The KNN model is instantiated with the parameter 'neighbours' set to 'tune()', indicative of a deliberate intention to identify the most optimal value for 'k' through subsequent tuning.\n",
    "\n",
    "4. **Workflow Integration:**\n",
    "   The recipe and the KNN model are seamlessly integrated into a workflow, with the 'tune_grid' function employed to systematically explore a range of 'k' values specified in 'gridvals' during cross-validation.\n",
    "\n",
    "5. **Determining Optimal k:**\n",
    "   The optimal 'k' value is discerned by filtering for accuracy and visualizing the accuracy estimate against the 'k' values through a line plot. This graphical representation serves to elucidate the relationship between 'k' and accuracy, guiding the selection of the most advantageous 'k' value.\n",
    "\n",
    "6. **Model Evaluation and Validation:**\n",
    "   Rigorous evaluation ensues to ensure that the selected 'k' value averts both underfitting and overfitting. Furthermore, a comparative analysis against a majority classifier is conducted to validate the efficacy of our model, affirming its superiority in predictive accuracy.\n",
    "\n",
    "This methodological framework adheres to rigorous standards, leveraging cross-validation and systematic exploration to identify the optimal 'k' for the KNN algorithm, thus enhancing the robustness and reliability of our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53630bd5-955b-413e-90a9-941f24ed415c",
   "metadata": {},
   "source": [
    "### Visualizing our results\n",
    "\n",
    "To visualize our results, we plotted max heart rate on the x-axis and cholesterol levels on the y-axis, using diagnosis to colour the points.\n",
    "\n",
    "To check for over/underfitting, we coloured the background of the graph based on what prediction would be made at every possible point. This also allowed us to quickly identify how the model classified patients, and where the boundaries were."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45fa8a-3db0-4f22-ac74-952f518b5741",
   "metadata": {},
   "source": [
    "### Testing our classifier\n",
    "\n",
    "Made a new model specification for the best  value chosen, combined with the recipe made earlier in a workflow, and fit the classifier to our training set.\n",
    "\n",
    "Used predict on the testing set to evaluate the classifier's predicition accuracy on data it hadn't seen before.\n",
    "\n",
    "Produced a confusion matrix to get a sense of which diagnoses the classifier was more accurate at giving, and what effects that has on real world application.\n",
    "\n",
    "Tested the accuracy of our classifier when given data from Hungary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908e655-b38a-48e8-862d-bc53f9978451",
   "metadata": {},
   "source": [
    "## Preprocessing and exploratory data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684d36c0-d5ee-4b96-a210-50091a793340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.2.1     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.3.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.0.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.1     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.3     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.1.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.4     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Search for functions across packages at \u001b[32mhttps://www.tidymodels.org/find/\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(RColorBrewer)\n",
    "\n",
    "# formatting graphs\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8622fa17-da37-4bfd-80a5-5686d83a6025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m294\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (9): X4, X5, X6, X7, X8, X9, X11, X12, X13\n",
      "\u001b[32mdbl\u001b[39m (5): X1, X2, X3, X10, X14\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>X4</th><th scope=col>X5</th><th scope=col>X6</th><th scope=col>X7</th><th scope=col>X8</th><th scope=col>X9</th><th scope=col>X10</th><th scope=col>X11</th><th scope=col>X12</th><th scope=col>X13</th><th scope=col>X14</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>28</td><td>1</td><td>2</td><td>130</td><td>132</td><td>0</td><td>2</td><td>185</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "\t<tr><td>29</td><td>1</td><td>2</td><td>120</td><td>243</td><td>0</td><td>0</td><td>160</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "\t<tr><td>29</td><td>1</td><td>2</td><td>140</td><td>?  </td><td>0</td><td>0</td><td>170</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "\t<tr><td>30</td><td>0</td><td>1</td><td>170</td><td>237</td><td>0</td><td>1</td><td>170</td><td>0</td><td>0</td><td>?</td><td>?</td><td>6</td><td>0</td></tr>\n",
       "\t<tr><td>31</td><td>0</td><td>2</td><td>100</td><td>219</td><td>0</td><td>1</td><td>150</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "\t<tr><td>32</td><td>0</td><td>2</td><td>105</td><td>198</td><td>0</td><td>0</td><td>165</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 14\n",
       "\\begin{tabular}{llllllllllllll}\n",
       " X1 & X2 & X3 & X4 & X5 & X6 & X7 & X8 & X9 & X10 & X11 & X12 & X13 & X14\\\\\n",
       " <dbl> & <dbl> & <dbl> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <dbl> & <chr> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 28 & 1 & 2 & 130 & 132 & 0 & 2 & 185 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\t 29 & 1 & 2 & 120 & 243 & 0 & 0 & 160 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\t 29 & 1 & 2 & 140 & ?   & 0 & 0 & 170 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\t 30 & 0 & 1 & 170 & 237 & 0 & 1 & 170 & 0 & 0 & ? & ? & 6 & 0\\\\\n",
       "\t 31 & 0 & 2 & 100 & 219 & 0 & 1 & 150 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\t 32 & 0 & 2 & 105 & 198 & 0 & 0 & 165 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 14\n",
       "\n",
       "| X1 &lt;dbl&gt; | X2 &lt;dbl&gt; | X3 &lt;dbl&gt; | X4 &lt;chr&gt; | X5 &lt;chr&gt; | X6 &lt;chr&gt; | X7 &lt;chr&gt; | X8 &lt;chr&gt; | X9 &lt;chr&gt; | X10 &lt;dbl&gt; | X11 &lt;chr&gt; | X12 &lt;chr&gt; | X13 &lt;chr&gt; | X14 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 28 | 1 | 2 | 130 | 132 | 0 | 2 | 185 | 0 | 0 | ? | ? | ? | 0 |\n",
       "| 29 | 1 | 2 | 120 | 243 | 0 | 0 | 160 | 0 | 0 | ? | ? | ? | 0 |\n",
       "| 29 | 1 | 2 | 140 | ?   | 0 | 0 | 170 | 0 | 0 | ? | ? | ? | 0 |\n",
       "| 30 | 0 | 1 | 170 | 237 | 0 | 1 | 170 | 0 | 0 | ? | ? | 6 | 0 |\n",
       "| 31 | 0 | 2 | 100 | 219 | 0 | 1 | 150 | 0 | 0 | ? | ? | ? | 0 |\n",
       "| 32 | 0 | 2 | 105 | 198 | 0 | 0 | 165 | 0 | 0 | ? | ? | ? | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  X1 X2 X3 X4  X5  X6 X7 X8  X9 X10 X11 X12 X13 X14\n",
       "1 28 1  2  130 132 0  2  185 0  0   ?   ?   ?   0  \n",
       "2 29 1  2  120 243 0  0  160 0  0   ?   ?   ?   0  \n",
       "3 29 1  2  140 ?   0  0  170 0  0   ?   ?   ?   0  \n",
       "4 30 0  1  170 237 0  1  170 0  0   ?   ?   6   0  \n",
       "5 31 0  2  100 219 0  1  150 0  0   ?   ?   ?   0  \n",
       "6 32 0  2  105 198 0  0  165 0  0   ?   ?   ?   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "294"
      ],
      "text/latex": [
       "294"
      ],
      "text/markdown": [
       "294"
      ],
      "text/plain": [
       "[1] 294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hungarian_data <- read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\",\n",
    "                          col_names = FALSE)\n",
    "\n",
    "head(hungarian_data)\n",
    "\n",
    "nrow(hungarian_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e65ea-cf1a-488f-a9e6-10773f237be1",
   "metadata": {},
   "source": [
    "figure 1\n",
    "\n",
    "As you can see above, the dataframe does not come with column names, so those must be added. Some factor columns are also being read as <dbl> or <chr>, so those need to be changed as well.\n",
    "\n",
    "The publisher tells us that each column is numeric-valued and there are 294 rows, with missing data represented as the string \"?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd13770-3d7a-445a-b7a5-8ff1cbecca1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
