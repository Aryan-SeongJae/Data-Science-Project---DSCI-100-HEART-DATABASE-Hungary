{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4306fd-3465-40e0-8d17-0f4f332e0587",
   "metadata": {},
   "source": [
    "# **Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d1811-944c-423a-b4f3-faf2378be21c",
   "metadata": {},
   "source": [
    "# **SERUM CHOLESTROL AND MAXIMUM HEART RATE ACHIEVED TO DIAGNOSE HEART DISEASE PATIENTS FROM HUNGARY**\n",
    "\n",
    "Aryan Jain, Vibhav "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fab048-b878-4e5f-a53f-13e67e7d5826",
   "metadata": {},
   "source": [
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6fc719-81b5-48ad-8cee-3f5a4f45a7d3",
   "metadata": {},
   "source": [
    "Cardiovascular disease encompasses a spectrum of cardiac conditions originating from malfunctions within the cardiac and vascular systems. Among these, coronary artery disease (CAD) manifests when the arteries responsible for supplying blood to the heart undergo a narrowing process. Numerous risk factors contribute to the predisposition for this malady, including elevated cholesterol levels and the maximum heart rate attained during physiological exertion.\n",
    "\n",
    "Elevated cholesterol levels precipitate the accumulation of lipid deposits within the vasculature, impeding the smooth flow of blood through the arteries. The rupture of these deposits may culminate in the formation of a thrombus, thereby instigating severe cardiovascular events such as myocardial infarction or stroke. Notably, individuals afflicted by heart disease may experience a notable reduction in their maximum heart rate, as indicated by medical insights provided by WebMD in 2002.\n",
    "\n",
    "In light of these considerations, the pertinent query arises: can the likelihood of an individual being afflicted by heart disease be ascertained based on an analysis of serum cholesterol levels and the maximum heart rate achieved? To address this question, we propose the utilization of a k-nearest neighbors (KNN) classifier algorithm, an analytical tool with demonstrated efficacy in pattern recognition and classification tasks. By employing this algorithm, we aim to discern discernible patterns and relationships between the aforementioned physiological parameters and the presence of heart disease in a new patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5459dc14-a8c6-4cfd-add2-1cfade13a79c",
   "metadata": {},
   "source": [
    "Our study involves the utilization of the \"processed.hungarian.data\" dataset extracted from the Heart Disease Database for the predictive assessment of heart disease presence in patients from Cleveland. The dataset comprises several pertinent variables, and our focus is on utilizing the variables \"chol\" (serum cholesterol level) and \"thalach\" (maximum heart rate achieved) as predictive features.\n",
    "\n",
    "The specific columns within the dataset are defined as follows:\n",
    "\n",
    "1. **age**: Age of the patient\n",
    "2. **sex**: Gender of the patient (1 = male, 0 = female)\n",
    "3. **cp**: Chest pain type\n",
    "4. **trestbps**: Resting blood pressure in mmHg\n",
    "5. **chol**: Serum cholesterol level in mg/dl\n",
    "6. **fbs**: Fasting blood sugar > 120 mg/dl? (1 = True, 0 = False)\n",
    "7. **restecg**: Resting electrocardiographic results\n",
    "8. **thalach**: Maximum heart rate achieved\n",
    "9. **exang**: Whether exercise induced angina (1 = True, 0 = False)\n",
    "10. **oldpeak**: ST depression induced by exercise, relative to rest\n",
    "11. **slope**: The slope of the peak exercise ST segment (1 = upslope, 2 = flat, 3 = downslope)\n",
    "12. **ca**: Number of major vessels (0-3) colored by fluoroscopy\n",
    "13. **thal**: Thalassemia classification (3 = normal, 6 = fixed defect, 7 = reversible defect)\n",
    "14. **num**: Diagnosis of heart disease (1, 2, 3, 4 = presence, 0 = no presence)\n",
    "\n",
    "For our analysis, we aim to employ the \"chol\" and \"thalach\" variables as predictors to discern the presence or absence of heart disease in patients. This predictive task aligns with the broader objective of leveraging relevant clinical data to enhance diagnostic capabilities and contribute to the advancement of cardiovascular health assessment methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f19f9d5-a7f9-4ee0-9d9d-9e12a74bba60",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "Data Preprocessing and Exploratory Data Analysis\n",
    "\n",
    "We initiated our study by importing relevant libraries and acquiring the \"processed.cleveland.data\" dataset from an authenticated online source. Subsequently, a meticulous data preprocessing phase ensued, wherein we applied systematic cleaning and tidying procedures to render the dataset amenable for analytical endeavors. This process involved judiciously assigning appropriate column types and introducing a new column labeled as \"diag\" to enhance the interpretability of the data.\n",
    "\n",
    "To facilitate subsequent analytical procedures, we judiciously partitioned the dataset into distinct training and testing sets. It is noteworthy that our analytical focus remained exclusively on the training set until the final stages of the investigation.\n",
    "\n",
    "A comprehensive summary of the training set was generated, laying the groundwork for subsequent predictive modeling. This involved the extraction of key insights and patterns from the training data to inform the desired behavior and performance criteria of our classifier.\n",
    "\n",
    "Visualization emerged as an integral component of our exploratory analysis. Specifically, we employed graphical representations to elucidate the intricate relationship between the variables \"thalac\" (maximum heart rate achieved) and \"chol\" (serum cholesterol level). This visual exploration was pivotal in fostering a nuanced understanding of the distributional characteristics inherent in the dataset, thereby contributing to the refinement of subsequent analytical strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43692b3e-d348-44f9-a599-d7202687fc9b",
   "metadata": {},
   "source": [
    "### Determining Optimal k for K-Nearest Neighbors Classifier\n",
    "\n",
    "The objective of this phase in our investigation is to ascertain the optimal value for the parameter 'k' in the k-nearest neighbors (KNN) algorithm, thereby maximizing the accuracy of our predictive model. The subsequent methodology encapsulates a systematic approach towards achieving this goal.\n",
    "\n",
    "1. **Data Preprocessing and Scaling:**\n",
    "   We commence by applying the recipe function to center and scale the training data, a crucial step in normalizing variables to a standardized range, facilitating robust and unbiased model training.\n",
    "\n",
    "2. **Cross-Validation Technique:**\n",
    "   Cross-validation, an integral aspect of our methodological framework, is executed with ten folds on the training dataset. This deliberate choice of employing ten folds serves to mitigate the influence of the specific observations in the validation set, thus enhancing the robustness and generalizability of our model.\n",
    "\n",
    "3. **K-Nearest Neighbors Model Initialization:**\n",
    "   The KNN model is instantiated with the parameter 'neighbours' set to 'tune()', indicative of a deliberate intention to identify the most optimal value for 'k' through subsequent tuning.\n",
    "\n",
    "4. **Workflow Integration:**\n",
    "   The recipe and the KNN model are seamlessly integrated into a workflow, with the 'tune_grid' function employed to systematically explore a range of 'k' values specified in 'gridvals' during cross-validation.\n",
    "\n",
    "5. **Determining Optimal k:**\n",
    "   The optimal 'k' value is discerned by filtering for accuracy and visualizing the accuracy estimate against the 'k' values through a line plot. This graphical representation serves to elucidate the relationship between 'k' and accuracy, guiding the selection of the most advantageous 'k' value.\n",
    "\n",
    "6. **Model Evaluation and Validation:**\n",
    "   Rigorous evaluation ensues to ensure that the selected 'k' value averts both underfitting and overfitting. Furthermore, a comparative analysis against a majority classifier is conducted to validate the efficacy of our model, affirming its superiority in predictive accuracy.\n",
    "\n",
    "This methodological framework adheres to rigorous standards, leveraging cross-validation and systematic exploration to identify the optimal 'k' for the KNN algorithm, thus enhancing the robustness and reliability of our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53630bd5-955b-413e-90a9-941f24ed415c",
   "metadata": {},
   "source": [
    "### Visualizing our results\n",
    "\n",
    "To visualize our results, we plotted max heart rate on the x-axis and cholesterol levels on the y-axis, using diagnosis to colour the points.\n",
    "\n",
    "To check for over/underfitting, we coloured the background of the graph based on what prediction would be made at every possible point. This also allowed us to quickly identify how the model classified patients, and where the boundaries were."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45fa8a-3db0-4f22-ac74-952f518b5741",
   "metadata": {},
   "source": [
    "### Testing our classifier\n",
    "\n",
    "Made a new model specification for the best  value chosen, combined with the recipe made earlier in a workflow, and fit the classifier to our training set.\n",
    "\n",
    "Used predict on the testing set to evaluate the classifier's predicition accuracy on data it hadn't seen before.\n",
    "\n",
    "Produced a confusion matrix to get a sense of which diagnoses the classifier was more accurate at giving, and what effects that has on real world application.\n",
    "\n",
    "Tested the accuracy of our classifier when given data from Hungary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908e655-b38a-48e8-862d-bc53f9978451",
   "metadata": {},
   "source": [
    "## Preprocessing and exploratory data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684d36c0-d5ee-4b96-a210-50091a793340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.2.1     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.3.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.0.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.1     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.3     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.1.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.4     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Learn how to get started at \u001b[32mhttps://www.tidymodels.org/start/\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(RColorBrewer)\n",
    "\n",
    "# formatting graphs\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8622fa17-da37-4bfd-80a5-5686d83a6025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m294\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (9): X4, X5, X6, X7, X8, X9, X11, X12, X13\n",
      "\u001b[32mdbl\u001b[39m (5): X1, X2, X3, X10, X14\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>X4</th><th scope=col>X5</th><th scope=col>X6</th><th scope=col>X7</th><th scope=col>X8</th><th scope=col>X9</th><th scope=col>X10</th><th scope=col>X11</th><th scope=col>X12</th><th scope=col>X13</th><th scope=col>X14</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>28</td><td>1</td><td>2</td><td>130</td><td>132</td><td>0</td><td>2</td><td>185</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "\t<tr><td>29</td><td>1</td><td>2</td><td>120</td><td>243</td><td>0</td><td>0</td><td>160</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "\t<tr><td>29</td><td>1</td><td>2</td><td>140</td><td>?  </td><td>0</td><td>0</td><td>170</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "\t<tr><td>30</td><td>0</td><td>1</td><td>170</td><td>237</td><td>0</td><td>1</td><td>170</td><td>0</td><td>0</td><td>?</td><td>?</td><td>6</td><td>0</td></tr>\n",
       "\t<tr><td>31</td><td>0</td><td>2</td><td>100</td><td>219</td><td>0</td><td>1</td><td>150</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "\t<tr><td>32</td><td>0</td><td>2</td><td>105</td><td>198</td><td>0</td><td>0</td><td>165</td><td>0</td><td>0</td><td>?</td><td>?</td><td>?</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 14\n",
       "\\begin{tabular}{llllllllllllll}\n",
       " X1 & X2 & X3 & X4 & X5 & X6 & X7 & X8 & X9 & X10 & X11 & X12 & X13 & X14\\\\\n",
       " <dbl> & <dbl> & <dbl> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <dbl> & <chr> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 28 & 1 & 2 & 130 & 132 & 0 & 2 & 185 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\t 29 & 1 & 2 & 120 & 243 & 0 & 0 & 160 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\t 29 & 1 & 2 & 140 & ?   & 0 & 0 & 170 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\t 30 & 0 & 1 & 170 & 237 & 0 & 1 & 170 & 0 & 0 & ? & ? & 6 & 0\\\\\n",
       "\t 31 & 0 & 2 & 100 & 219 & 0 & 1 & 150 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\t 32 & 0 & 2 & 105 & 198 & 0 & 0 & 165 & 0 & 0 & ? & ? & ? & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 14\n",
       "\n",
       "| X1 &lt;dbl&gt; | X2 &lt;dbl&gt; | X3 &lt;dbl&gt; | X4 &lt;chr&gt; | X5 &lt;chr&gt; | X6 &lt;chr&gt; | X7 &lt;chr&gt; | X8 &lt;chr&gt; | X9 &lt;chr&gt; | X10 &lt;dbl&gt; | X11 &lt;chr&gt; | X12 &lt;chr&gt; | X13 &lt;chr&gt; | X14 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 28 | 1 | 2 | 130 | 132 | 0 | 2 | 185 | 0 | 0 | ? | ? | ? | 0 |\n",
       "| 29 | 1 | 2 | 120 | 243 | 0 | 0 | 160 | 0 | 0 | ? | ? | ? | 0 |\n",
       "| 29 | 1 | 2 | 140 | ?   | 0 | 0 | 170 | 0 | 0 | ? | ? | ? | 0 |\n",
       "| 30 | 0 | 1 | 170 | 237 | 0 | 1 | 170 | 0 | 0 | ? | ? | 6 | 0 |\n",
       "| 31 | 0 | 2 | 100 | 219 | 0 | 1 | 150 | 0 | 0 | ? | ? | ? | 0 |\n",
       "| 32 | 0 | 2 | 105 | 198 | 0 | 0 | 165 | 0 | 0 | ? | ? | ? | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  X1 X2 X3 X4  X5  X6 X7 X8  X9 X10 X11 X12 X13 X14\n",
       "1 28 1  2  130 132 0  2  185 0  0   ?   ?   ?   0  \n",
       "2 29 1  2  120 243 0  0  160 0  0   ?   ?   ?   0  \n",
       "3 29 1  2  140 ?   0  0  170 0  0   ?   ?   ?   0  \n",
       "4 30 0  1  170 237 0  1  170 0  0   ?   ?   6   0  \n",
       "5 31 0  2  100 219 0  1  150 0  0   ?   ?   ?   0  \n",
       "6 32 0  2  105 198 0  0  165 0  0   ?   ?   ?   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "294"
      ],
      "text/latex": [
       "294"
      ],
      "text/markdown": [
       "294"
      ],
      "text/plain": [
       "[1] 294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hungarian_data <- read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data\",\n",
    "                          col_names = FALSE)\n",
    "\n",
    "head(hungarian_data)\n",
    "\n",
    "nrow(hungarian_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e65ea-cf1a-488f-a9e6-10773f237be1",
   "metadata": {},
   "source": [
    "figure 1\n",
    "\n",
    "As you can see above, the dataframe does not come with column names, so those must be added. Some factor columns are also being read as <dbl> or <chr>, so those need to be changed as well.\n",
    "\n",
    "The publisher tells us that each column is numeric-valued and there are 294 rows, with missing data represented as the string \"?\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5669b-f537-465d-8f52-3e14252149ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Cleaning and Structuring\n",
    "\n",
    "The presence of \"<chr>\" data types in certain columns is attributed to the inclusion of \"?\" as placeholders for unknown values. In order to facilitate appropriate data type assignment, we undertake a meticulous data cleaning process wherein these \"?\" entries are systematically replaced with NA values.\n",
    "\n",
    "Furthermore, to enhance the clinical relevance of our analysis, a binary diagnostic column, denoted as \"diag,\" is introduced. While the existing variable \"num\" categorizes heart disease by severity, with 0 indicating the absence of the condition, the \"diag\" variable transcends severity levels. It serves the purpose of classifying patients into two categories—those with or without heart disease. This binary classification, irrespective of disease severity, is imperative in practical healthcare scenarios, as it prompts medical attention and potential treatment recommendations for any manifestation of heart disease. The introduction of the \"diag\" column underscores the translational utility of our analysis in real-world healthcare contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954ba9e0-d854-4b10-8df2-a5df7d07851d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 15</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>age</th><th scope=col>sex</th><th scope=col>cp</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>thalach</th><th scope=col>exang</th><th scope=col>oldpeak</th><th scope=col>slope</th><th scope=col>ca</th><th scope=col>thal</th><th scope=col>num</th><th scope=col>diag</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>28</td><td>1</td><td>2</td><td>130</td><td>132</td><td>0</td><td>2</td><td>185</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>29</td><td>1</td><td>2</td><td>120</td><td>243</td><td>0</td><td>0</td><td>160</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>29</td><td>1</td><td>2</td><td>140</td><td>NA </td><td>0</td><td>0</td><td>170</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>30</td><td>0</td><td>1</td><td>170</td><td>237</td><td>0</td><td>1</td><td>170</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>6 </td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>31</td><td>0</td><td>2</td><td>100</td><td>219</td><td>0</td><td>1</td><td>150</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>32</td><td>0</td><td>2</td><td>105</td><td>198</td><td>0</td><td>0</td><td>165</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 15\n",
       "\\begin{tabular}{lllllllllllllll}\n",
       " age & sex & cp & trestbps & chol & fbs & restecg & thalach & exang & oldpeak & slope & ca & thal & num & diag\\\\\n",
       " <dbl> & <fct> & <fct> & <chr> & <chr> & <fct> & <fct> & <chr> & <fct> & <dbl> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t 28 & 1 & 2 & 130 & 132 & 0 & 2 & 185 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 29 & 1 & 2 & 120 & 243 & 0 & 0 & 160 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 29 & 1 & 2 & 140 & NA  & 0 & 0 & 170 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 30 & 0 & 1 & 170 & 237 & 0 & 1 & 170 & 0 & 0 & NA & NA & 6  & 0 & FALSE\\\\\n",
       "\t 31 & 0 & 2 & 100 & 219 & 0 & 1 & 150 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 32 & 0 & 2 & 105 & 198 & 0 & 0 & 165 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 15\n",
       "\n",
       "| age &lt;dbl&gt; | sex &lt;fct&gt; | cp &lt;fct&gt; | trestbps &lt;chr&gt; | chol &lt;chr&gt; | fbs &lt;fct&gt; | restecg &lt;fct&gt; | thalach &lt;chr&gt; | exang &lt;fct&gt; | oldpeak &lt;dbl&gt; | slope &lt;fct&gt; | ca &lt;fct&gt; | thal &lt;fct&gt; | num &lt;fct&gt; | diag &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 28 | 1 | 2 | 130 | 132 | 0 | 2 | 185 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 29 | 1 | 2 | 120 | 243 | 0 | 0 | 160 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 29 | 1 | 2 | 140 | NA  | 0 | 0 | 170 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 30 | 0 | 1 | 170 | 237 | 0 | 1 | 170 | 0 | 0 | NA | NA | 6  | 0 | FALSE |\n",
       "| 31 | 0 | 2 | 100 | 219 | 0 | 1 | 150 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 32 | 0 | 2 | 105 | 198 | 0 | 0 | 165 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "\n"
      ],
      "text/plain": [
       "  age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal num\n",
       "1 28  1   2  130      132  0   2       185     0     0       NA    NA NA   0  \n",
       "2 29  1   2  120      243  0   0       160     0     0       NA    NA NA   0  \n",
       "3 29  1   2  140      NA   0   0       170     0     0       NA    NA NA   0  \n",
       "4 30  0   1  170      237  0   1       170     0     0       NA    NA 6    0  \n",
       "5 31  0   2  100      219  0   1       150     0     0       NA    NA NA   0  \n",
       "6 32  0   2  105      198  0   0       165     0     0       NA    NA NA   0  \n",
       "  diag \n",
       "1 FALSE\n",
       "2 FALSE\n",
       "3 FALSE\n",
       "4 FALSE\n",
       "5 FALSE\n",
       "6 FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "# assigning col names\n",
    "hungarian_clean <- hungarian_data\n",
    "\n",
    "colnames(hungarian_clean) <- c(\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \n",
    "                               \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\")\n",
    "                           \n",
    "# changing \"?\" into NA\n",
    "hungarian_clean[ hungarian_clean == \"?\" ] <- NA\n",
    "\n",
    "# adding diag column, setting col types\n",
    "# as.integer is being used to get rid of decimal points when switching to factor\n",
    "hungarian_clean <- hungarian_clean |>\n",
    "                    mutate(diag = as.factor(ifelse(is.na(num), NA, (num > 0)))) |>\n",
    "                    mutate(sex = as.factor(as.integer(sex)), cp = as.factor(as.integer(cp)), \n",
    "                            fbs = as.factor(as.integer(fbs)), restecg = as.factor(as.integer(restecg)),\n",
    "                            exang = as.factor(as.integer(exang)), thal = as.factor(as.integer(thal)),\n",
    "                            ca = as.factor(as.integer(ca)), slope = as.factor(as.integer(slope))) |>\n",
    "                     mutate(num = as_factor(num))\n",
    "\n",
    "head(hungarian_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc071696-c13a-48a6-baa1-1abf7130ce23",
   "metadata": {},
   "source": [
    "figure 2\n",
    "\n",
    "Now our data is clean and tidy!\n",
    "\n",
    "Since num uses integers to distinguish presence (1,2,3,4) from absence (0), and we want to determine whether or not a patient has heart disease, a new boolean column diag has been appended to narrow diagnoses down to TRUE or FALSE. To be able to stratify by it, we made it a factor column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af3706-7866-4e3e-b1b3-508a3aeba9e8",
   "metadata": {},
   "source": [
    "#### Splitting our data into training and testing sets\n",
    "\n",
    "Before working on our model, we need to split our data into training and testing sets. Since we want to predict the new column diag, we will be stratifying by it.\n",
    "\n",
    "We will use initial_split to split our dataframe into 75% training and 25% testing, since it shuffles our data for us and ensures an constant proportion of each class is present in both. The 75-25 split allows us to train our model on as many data points as possible while also keeping enough data for effective testing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9d68cdb-af3a-4a8e-886e-653ea007945b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 15</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>age</th><th scope=col>sex</th><th scope=col>cp</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>thalach</th><th scope=col>exang</th><th scope=col>oldpeak</th><th scope=col>slope</th><th scope=col>ca</th><th scope=col>thal</th><th scope=col>num</th><th scope=col>diag</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>28</td><td>1</td><td>2</td><td>130</td><td>132</td><td>0</td><td>2</td><td>185</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>29</td><td>1</td><td>2</td><td>120</td><td>243</td><td>0</td><td>0</td><td>160</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>32</td><td>1</td><td>2</td><td>110</td><td>225</td><td>0</td><td>0</td><td>184</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>34</td><td>0</td><td>2</td><td>130</td><td>161</td><td>0</td><td>0</td><td>190</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>35</td><td>0</td><td>1</td><td>120</td><td>160</td><td>0</td><td>1</td><td>185</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "\t<tr><td>35</td><td>0</td><td>4</td><td>140</td><td>167</td><td>0</td><td>0</td><td>150</td><td>0</td><td>0</td><td>NA</td><td>NA</td><td>NA</td><td>0</td><td>FALSE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 15\n",
       "\\begin{tabular}{lllllllllllllll}\n",
       " age & sex & cp & trestbps & chol & fbs & restecg & thalach & exang & oldpeak & slope & ca & thal & num & diag\\\\\n",
       " <dbl> & <fct> & <fct> & <chr> & <chr> & <fct> & <fct> & <chr> & <fct> & <dbl> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t 28 & 1 & 2 & 130 & 132 & 0 & 2 & 185 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 29 & 1 & 2 & 120 & 243 & 0 & 0 & 160 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 32 & 1 & 2 & 110 & 225 & 0 & 0 & 184 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 34 & 0 & 2 & 130 & 161 & 0 & 0 & 190 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 35 & 0 & 1 & 120 & 160 & 0 & 1 & 185 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\t 35 & 0 & 4 & 140 & 167 & 0 & 0 & 150 & 0 & 0 & NA & NA & NA & 0 & FALSE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 15\n",
       "\n",
       "| age &lt;dbl&gt; | sex &lt;fct&gt; | cp &lt;fct&gt; | trestbps &lt;chr&gt; | chol &lt;chr&gt; | fbs &lt;fct&gt; | restecg &lt;fct&gt; | thalach &lt;chr&gt; | exang &lt;fct&gt; | oldpeak &lt;dbl&gt; | slope &lt;fct&gt; | ca &lt;fct&gt; | thal &lt;fct&gt; | num &lt;fct&gt; | diag &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 28 | 1 | 2 | 130 | 132 | 0 | 2 | 185 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 29 | 1 | 2 | 120 | 243 | 0 | 0 | 160 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 32 | 1 | 2 | 110 | 225 | 0 | 0 | 184 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 34 | 0 | 2 | 130 | 161 | 0 | 0 | 190 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 35 | 0 | 1 | 120 | 160 | 0 | 1 | 185 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "| 35 | 0 | 4 | 140 | 167 | 0 | 0 | 150 | 0 | 0 | NA | NA | NA | 0 | FALSE |\n",
       "\n"
      ],
      "text/plain": [
       "  age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal num\n",
       "1 28  1   2  130      132  0   2       185     0     0       NA    NA NA   0  \n",
       "2 29  1   2  120      243  0   0       160     0     0       NA    NA NA   0  \n",
       "3 32  1   2  110      225  0   0       184     0     0       NA    NA NA   0  \n",
       "4 34  0   2  130      161  0   0       190     0     0       NA    NA NA   0  \n",
       "5 35  0   1  120      160  0   1       185     0     0       NA    NA NA   0  \n",
       "6 35  0   4  140      167  0   0       150     0     0       NA    NA NA   0  \n",
       "  diag \n",
       "1 FALSE\n",
       "2 FALSE\n",
       "3 FALSE\n",
       "4 FALSE\n",
       "5 FALSE\n",
       "6 FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "220"
      ],
      "text/latex": [
       "220"
      ],
      "text/markdown": [
       "220"
      ],
      "text/plain": [
       "[1] 220"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "74"
      ],
      "text/latex": [
       "74"
      ],
      "text/markdown": [
       "74"
      ],
      "text/plain": [
       "[1] 74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#splitting dataframe into training, testing datasets\n",
    "hungarian_split <- initial_split(hungarian_clean, prop = 3/4, strata = diag)\n",
    "\n",
    "hungarian_training <- training(hungarian_split)\n",
    "hungarian_testing <- testing(hungarian_split)\n",
    "\n",
    "head(hungarian_training)\n",
    "\n",
    "nrow(hungarian_training)\n",
    "nrow(hungarian_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2554f-d52d-4e98-83ea-b2ef14bb2092",
   "metadata": {},
   "source": [
    "figure 3\n",
    "\n",
    "In the above code, we split the data into a training set to build our model on, and a testing set to, well, test it. Using initial_split allowed us to shuffle the data before splitting (removing bias and order) and stratify the data by diag so that an equal proportion of each is in each set.\n",
    "\n",
    "There are 220 rows (75%) in the training set and 74 rows (25%) in the testing set. This gives us enough data to train the classifier on, as well as enough to test it on later. This means our classifier is going to be reliable.\n",
    "\n",
    "Moving forward, we will only use the training set until the very end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29793b3a-f329-4b9b-ab21-2ebd2383b653",
   "metadata": {},
   "source": [
    "### Summarizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e9d491-17a3-47ef-bfd1-c40240b5dc27",
   "metadata": {},
   "source": [
    "Before we get to work, we need to make sure that the two classes actually have different averages in serum cholersterol and maximum heart rate achieved.\n",
    "\n",
    "To do this, we will use group_by and summarize to create a table with the minimum, maximum and mean of each of our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aa1f895-37e4-49c8-9730-120d0aa806e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“\u001b[1m\u001b[22mThere were 4 warnings in `summarize()`.\n",
      "The first warning was:\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m In argument: `mean_chol = mean(chol)`.\n",
      "\u001b[36mℹ\u001b[39m In group 1: `diag = FALSE`.\n",
      "Caused by warning in `mean.default()`:\n",
      "\u001b[33m!\u001b[39m argument is not numeric or logical: returning NA\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m Run `dplyr::last_dplyr_warnings()` to see the 3 remaining warnings.”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>diag</th><th scope=col>mean_chol</th><th scope=col>mean_thalach</th><th scope=col>n_of_patients</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>FALSE</td><td>NA</td><td>NA</td><td>141</td></tr>\n",
       "\t<tr><td>TRUE </td><td>NA</td><td>NA</td><td> 79</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 × 4\n",
       "\\begin{tabular}{llll}\n",
       " diag & mean\\_chol & mean\\_thalach & n\\_of\\_patients\\\\\n",
       " <fct> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t FALSE & NA & NA & 141\\\\\n",
       "\t TRUE  & NA & NA &  79\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 × 4\n",
       "\n",
       "| diag &lt;fct&gt; | mean_chol &lt;dbl&gt; | mean_thalach &lt;dbl&gt; | n_of_patients &lt;int&gt; |\n",
       "|---|---|---|---|\n",
       "| FALSE | NA | NA | 141 |\n",
       "| TRUE  | NA | NA |  79 |\n",
       "\n"
      ],
      "text/plain": [
       "  diag  mean_chol mean_thalach n_of_patients\n",
       "1 FALSE NA        NA           141          \n",
       "2 TRUE  NA        NA            79          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#summarizing to get min, max, mean of each predictor + total no. of rows per class\n",
    "hungarian_summary <- hungarian_training %>%\n",
    "                    group_by(diag) %>%\n",
    "                    summarize(mean_chol = mean(chol), \n",
    "                              mean_thalach = mean(thalach),\n",
    "                              n_of_patients = n())\n",
    "\n",
    "hungarian_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c26f8-e5c4-4c46-b6e9-613fa836aab2",
   "metadata": {},
   "source": [
    "figure 4\n",
    "\n",
    "To summarize our data, we grouped by diag then summarized for the minimum, maximum and mean of chol and thalach.\n",
    "\n",
    "We can see that patients with heart disease tend to have higher cholesterol and lower maximum heart rates. Therefore, these trends are what we expect our classifier to predict diagnoses using later. We can also see that the number of TRUE and FALSE diagnoses are roughly balanced in the training set, which means our classifier is unlikely to be biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a6e74-adb2-4058-952b-5aeb5311901e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
